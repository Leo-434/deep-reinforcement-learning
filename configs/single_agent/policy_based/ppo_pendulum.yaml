algo:
  name: "PPO"

env:
  env_id: "Pendulum-v1"
  log_dir: "logs/ppo_pendulum"
  save_dir: "models/ppo_pendulum"
  seed: 42
  num_actions: 1

network:
  hidden_dims: [64, 64]

buffer:
  capacity: 2048 # PPO rollout buffer size per update

exploration:
  std_init: 1.0 # Will map to log_std inside policy

target:
  gamma: 0.99
  gae_lambda: 0.95

optim:
  lr: 0.0003
  max_grad_norm: 0.5

training:
  max_steps: 50000
  learning_starts: 2048
  batch_size: 64
  train_freq: 2048 # Update policy every N steps using on-policy data
  save_freq: 25000
  ppo_epochs: 10
  clip_range: 0.2
  vf_coef: 0.5
  ent_coef: 0.01

